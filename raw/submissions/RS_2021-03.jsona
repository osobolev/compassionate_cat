{"all_awardings":[],"allow_live_comments":false,"archived":false,"author":"Compassionate_Cat","author_created_utc":1531606232,"author_flair_background_color":null,"author_flair_css_class":null,"author_flair_richtext":[],"author_flair_template_id":null,"author_flair_text":null,"author_flair_text_color":null,"author_flair_type":"text","author_fullname":"t2_1rxgevrs","author_patreon_flair":false,"author_premium":false,"can_gild":true,"category":null,"content_categories":null,"contest_mode":false,"created_utc":1614767568,"discussion_type":null,"distinguished":null,"domain":"self.promortalism","edited":false,"gilded":0,"gildings":{},"hidden":false,"hide_score":false,"id":"lwqrzg","is_created_from_ads_ui":false,"is_crosspostable":true,"is_meta":false,"is_original_content":false,"is_reddit_media_domain":false,"is_robot_indexable":true,"is_self":true,"is_video":false,"link_flair_background_color":"","link_flair_css_class":null,"link_flair_richtext":[],"link_flair_text":null,"link_flair_text_color":"dark","link_flair_type":"text","locked":false,"media":null,"media_embed":{},"media_only":false,"name":"t3_lwqrzg","no_follow":false,"num_comments":4,"num_crossposts":0,"over_18":false,"parent_whitelist_status":null,"permalink":"\/r\/promortalism\/comments\/lwqrzg\/a_promortalist_intuition_ive_entertained_for_the\/","pinned":false,"pwls":null,"quarantine":false,"removed_by_category":null,"retrieved_utc":1623408777,"score":12,"secure_media":null,"secure_media_embed":{},"selftext":"I don't have a firm position on PM, much like my AN is not firm, but I think if I was certain of a few conditions about the world, they easily flip my ethics on these topics.\n\nI believe that evil inevitably takes over all game-like substrates. The word \"substrate\" is important here because it specifies that there's some base physics that produces this game, and this game is not a meta-game(where we can create rules, like Chess. It's not meaningful to say \"Evil takes over Chess\" for instance-- we have referees and cheaters are disqualified reliably, although I do actually loosely believe this to be true of Chess, albeit in a convoluted way). Any system which can be called a game that forms out of some physics, so no referee or judge to enforce the rules, means that the most skilled rule-breakers of the game(The term \"rule breaker\" here meaning \"Maximizing move availability and execution\"-- so to ground this, if a rule is \"Don't torture people\", two entities which are equal in every way except one can break the rule \"Don't torture\" and the other can't, the one which can, is at an advantage in the game), insofar as they don't break the rule called \"Win\", win the game\n\nIf the above is true about this reality, then not only is natalism futile, and death is good, but this sort of world almost demands death. In that sort of world, death is an emergency, but there's a memetic dilemma because every moment spent alive has various costs and benefits. The greatest cost of staying alive, in ethical terms in this universe, is every expression you make in this universe is to support an evil hierarchy. This extends beyond veganism and antinatalism, which people understand but... there are no \"anti-informationists\". That means, every effort spent making things better could be paving the road to hell(with good intentions). Every thought, every reddit post, every movement throughout the world, could be net negative and it could simply be an emergency to die.\n\nTo try to ground this part, I'm going to have to give a crappy analogy but, imagine... I don't know, your preferred popular fiction book\/movie\/etc setting with an evil antagonist front-runner and a good protagonist underdog. It really doesn't matter which one you pick. Forget the canonical, inevitable \"Team: Good wins\" here, since we're describing a scenario where evil always wins. Now imagine the evil team with their evil ruler, and the relationship they have with the world-- goodness only exists here to stress test the \"immune response\" of evil. They can't ever beat evil, and they would be better off not fighting evil. They shouldn't go to the local socializing grounds(or, reddit), to discuss evil, to plan against evil, or even just to hang out and be merry and create this illusion that this isn't an evil world with an evil winner, because &lt;insert your favorite evil mastermind&gt; is literally reading everything, assimilating it, strengthening himself from it, etc etc. In that sort of world, **everything you do**, apart from die, leads to a worse scenario than death. But then one could say, but what if one dedicates themselves to pro-mortalism in such a world? Could that be better than immediate death? How long should one wait, existing purely as a viral agent containing the sole meme \"Death is an emergency\"? From there, it becomes purely another game, where one attempts to min-max time spent alive vs. time spent maximizing the meme of death.\n\nIf our world is this sort of \"Death is an emergency\" world, for instance, this entire post could have been net negative ethically in comparison to simply having committed suicide instead of writing it. This is more or less the representation I've been entertaining, so I wanted to( irresponsibly, after having written this ), share it.","send_replies":true,"spoiler":false,"stickied":false,"subreddit":"promortalism","subreddit_id":"t5_3i342","subreddit_subscribers":717,"subreddit_type":"public","suggested_sort":null,"thumbnail":"self","thumbnail_height":null,"thumbnail_width":null,"title":"A pro-mortalist intuition I've entertained for the two or so years","top_awarded_type":null,"total_awards_received":0,"treatment_tags":[],"upvote_ratio":0.94,"url":"https:\/\/www.reddit.com\/r\/promortalism\/comments\/lwqrzg\/a_promortalist_intuition_ive_entertained_for_the\/","whitelist_status":null,"wls":null}
{"all_awardings":[],"allow_live_comments":true,"archived":false,"author":"Compassionate_Cat","author_created_utc":1531606232,"author_flair_background_color":null,"author_flair_css_class":null,"author_flair_richtext":[],"author_flair_template_id":null,"author_flair_text":null,"author_flair_text_color":null,"author_flair_type":"text","author_fullname":"t2_1rxgevrs","author_patreon_flair":false,"author_premium":false,"can_gild":true,"category":null,"content_categories":null,"contest_mode":false,"created_utc":1615189395,"discussion_type":null,"distinguished":null,"domain":"self.Efilism","edited":1615734230.0,"gilded":0,"gildings":{},"hidden":false,"hide_score":false,"id":"m0ap1c","is_created_from_ads_ui":false,"is_crosspostable":true,"is_meta":false,"is_original_content":false,"is_reddit_media_domain":false,"is_robot_indexable":true,"is_self":true,"is_video":false,"link_flair_background_color":"","link_flair_css_class":null,"link_flair_richtext":[],"link_flair_text":null,"link_flair_text_color":"dark","link_flair_type":"text","locked":false,"media":null,"media_embed":{},"media_only":false,"name":"t3_m0ap1c","no_follow":false,"num_comments":33,"num_crossposts":0,"over_18":false,"parent_whitelist_status":"no_ads","permalink":"\/r\/Efilism\/comments\/m0ap1c\/the_idea_of_unintelligent_design_and_why_it_is\/","pinned":false,"pwls":0,"quarantine":false,"removed_by_category":null,"retrieved_utc":1623415334,"score":8,"secure_media":null,"secure_media_embed":{},"selftext":"I found myself observing a philosophical discussion where one party accused the other of low intelligence. This reminded me of a question I was asked recently by a member of this subreddit about my thoughts on \"Unintelligent Design\" and my general thoughts on Efilism. I don't think I fully covered my thinking in our exchange, and I had an opportunity to share those thoughts elsewhere, so I will repost this here.\n\nI do not find the idea of \"Unintelligent Design\" compelling because it is *value* laden. It assumes that intelligence \"Gets the right answer\". I think this is a misunderstanding of what intelligence is. Intelligence can help one solve errors, but ultimately it is not enough to not be mistaken except in the most ideal sense(omniscience). Let's call my example \"Genius Sharks\"(reposted from the AN discord):\n\n&gt; Traits ultimately determine our views on reality, and genes\/environment determine our traits, and I argue that traits limit one's ability to navigate reality more than IQ does. The way I try to trigger this intuition is I ask: \"What is the difference, functionally, between stupidity and the traits of fearlessness, low risk aversion, and sadomasochism?\"\n\n&gt;The question is a sort of trick question because the point is there's not a whole lot of difference. Imagine a great white shark attacking a very small boat with a person on it equipped with a harpoon gun. If the shark attacks the boat, the person will harpoon it in the face, likely killing it. The shark has low intelligence by our standards, it does not understand this consequence.\n\n&gt;But it does have the psychopathic traits of fearlessness, low-risk aversion( by definition), and a weak\/loose version of sadomasochism(It is motivated to ultimately cause suffering by being motivated by predatory incentives, but is also not terribly motivated to avoid it-- it doesn't cry if you hurt it, and any aversion is relatively weak here, predators are just a genetic script that maximizes \"Kill kill kill\"). What would happen if you were to gradually increase this sharks intelligence to the point where it understands what a harpoon gun is, or has the ability to process consequences like attacking the boat?\n\n&gt;Many people would intuitively guess the shark would not attack the boat because it doesn't want to die and is smart. But the heavy lifting is actually done by the traits, not the intelligence. The total traits make it a domination machine. It's trying to \"win\" genetically, and the genes formulate a strategy that throws the shark into the meat grinder of reality until one slips through unharmed, whose genes then spread, and then the ecosystem adapts accordingly. That's what the genes are doing with traits like fearlessness, sadomasochism, low risk aversion, no self-awareness, etc. \n\n&gt;The shark still attacks the boat for the same reason serial killers like Ted Bundy and countless other psychopaths find themselves either being executed by the prison system or in conflicts with other people. The genes don't care about the psychopath who gets executed or killed, they are playing a \"long game\". The mortality rate for psychopaths under 40 is 33 times higher than for non-psychopaths. To understand this in Gary's terms, psychopathy is more \"Meat-grindy\" than other genetic strategies.\n\n&gt;You could give the shark 200 human IQ, and if it's psychopathic traits are high enough, it will still attack the boat to get harpooned in the face. The reason is because it values terrorizing boats as a survival strategy, and doesn't value \"Not getting harpooned in the face\".\n\n&gt;The shark loses here in the short term of course, since it will suffer and die due to its genetic expression(a kind of stupidity, which is why intelligence doesn't save the shark and why intelligence is not this... amazing 'antidote' to problems that we think it is). But in the long term, the genes either win or die off giving it a really strong effort.\n\nYou can really test this idea by imagining a being with evil traits(remember, traits have a causal relationship with behavior), *near* total omniscience, where the gap in omniscience exists purely in an ignorance of one's own traits being some version of evil(where evil is bad for everything)\/unfavorable\/unoptimal\/etc. Would near omniscience help such a being in so far as the traits drive it the wrong way? I personally don't see how, in any reliable way. This is why it's technically \"unintelligent design\" in the most ideal, unrealistic way, but in practical terms it's extremely intelligent design(without contradicting that it is unconscious design) for optimizing genes to dominate biological and post-biological systems. The genes are unconscious, yes, but the efficiency at which they propagate can't really be called \"Unintelligent\"--, if they were conscious, they would be called evil given how diabolically and expertly they dominated the environment-- anything but \"unintellingent\".","send_replies":true,"spoiler":false,"stickied":false,"subreddit":"Efilism","subreddit_id":"t5_2w5p7","subreddit_subscribers":3477,"subreddit_type":"public","suggested_sort":null,"thumbnail":"self","thumbnail_height":null,"thumbnail_width":null,"title":"The idea of \"Unintelligent Design\" and why it is flawed, and why this flaw is *not* even a problem for Efilism","top_awarded_type":null,"total_awards_received":0,"treatment_tags":[],"upvote_ratio":0.71,"url":"https:\/\/www.reddit.com\/r\/Efilism\/comments\/m0ap1c\/the_idea_of_unintelligent_design_and_why_it_is\/","whitelist_status":"no_ads","wls":0}
{"all_awardings":[],"allow_live_comments":false,"archived":false,"author":"Compassionate_Cat","author_created_utc":1531606232,"author_flair_background_color":null,"author_flair_css_class":null,"author_flair_richtext":[],"author_flair_template_id":null,"author_flair_text":null,"author_flair_text_color":null,"author_flair_type":"text","author_fullname":"t2_1rxgevrs","author_patreon_flair":false,"author_premium":false,"can_gild":true,"category":null,"content_categories":null,"contest_mode":false,"created_utc":1615551648,"discussion_type":null,"distinguished":null,"domain":"self.negativeutilitarians","edited":1615552270.0,"gilded":0,"gildings":{},"hidden":false,"hide_score":false,"id":"m3gfcc","is_created_from_ads_ui":false,"is_crosspostable":true,"is_meta":false,"is_original_content":false,"is_reddit_media_domain":false,"is_robot_indexable":true,"is_self":true,"is_video":false,"link_flair_background_color":"","link_flair_css_class":null,"link_flair_richtext":[],"link_flair_text":null,"link_flair_text_color":"dark","link_flair_type":"text","locked":false,"media":null,"media_embed":{},"media_only":false,"name":"t3_m3gfcc","no_follow":false,"num_comments":8,"num_crossposts":0,"over_18":false,"parent_whitelist_status":"no_ads","permalink":"\/r\/negativeutilitarians\/comments\/m3gfcc\/both_formal_and_informal_approaches_to_ethics_as\/","pinned":false,"pwls":0,"quarantine":false,"removed_by_category":null,"retrieved_utc":1623421114,"score":5,"secure_media":null,"secure_media_embed":{},"selftext":"Not in any reliable way. Just imagine how anyone at all approaches the ideas of philosophy, particularly ethics, down from the average person, to the career philosopher. They are born, with certain bound traits which will be expressed as genes. The environment then molds these traits to create a fairly coherent person. They attempt to reason about the world, and reach conclusions. \"Nothing matters\". \"Things matter\". \"Things matter in x way rather than y way\". What explains this representation? Is it their ability to reason? I think if anyone actually reaches ethical truth, they do so by accident. The person's traits color their representations of reality, but not necessarily vice versa. A truly evil human being cannot have truly good ethics, for example(not in any honest representation, obviously they can fake it-- but what they believe\/express deep down inside is determined by their nature). This does not guarantee that a good person has good ethics, of course, but this has more to do I think with the total nature of the species rather than anything else. In an ideal, hypothetical sense, this *would* be true, and a truly good thing *would* have truly good ethics, by definition(there are hairs to split with truly good things that express goodness by sheer accident, and then gradations of awareness and good intentions from here to more meaningfully represent the greater idea).\n\nThis applies to philosophy as a whole, of course. Take a ethics-adjacent idea like \"Free Will\". It should be clear that philosophers, and even very intelligent ones, could argue forever about this problem. I think there's a reason we have a \"hard problem of consciousness\" but not a \"hard problem of free will\"(other than to distinguish the hard\/soft problems of consciousness). Free will is simply this-- a certain ontology appears to person A, another completely incompatible ontology appears to person B, and both say \"This is not that complicated\" and insist their representation is right.\n\nIs there a better way to make sense of this problem? Philosophy, no matter if formal or informal, doesn't get us very far here. This is a \"game-ified\" problem where it's just an infinite regress arguing for\/against it. The answer lies in the traits of the individual making the claim. Jon Haidt is famous for his pop-psychology content which suggests that political divides in the U.S. are simply the product of different personalities\/values. Among many other traits, and to oversimply but get the point across, Conservatives are higher in Conscientiousness, Liberals are higher in Openness, etc etc, and differences like these explain why they arrive at different value systems and clash so aggressively. I think much of our understanding of the world can be explained this way.\n\nHow one arrives at a question like \"Do we have free will?\" is not determined by intelligence, or ability to reason, or something that can be reliably resolved through formal logic, it's purely based on your phenomenology. To someone who is fairly detached from a sense of self, lower in egocentrism, it'll be obvious that they're the witness of causal events and the idea will be incoherent. To someone deeply enchanted by the self, who feels like they're piloting some Cartesian robot, who feels like they really *earned* their position in life, then of course they will be convinced they can freely make choices. To conclude otherwise creates a kind of panic, and this neurosis is expressed with the tired line of \"No free will implies nihilism\". After the traits do their work is when these people invent very elaborate narratives and arguments for why we do or do not have free will. \n\nSpeculations: Ethics functions identically. If you're a diehard Nihilist or Utilitarian or a Negative Utilitarian or anything else, this **says something important** about who you are. It tells us what you value. To be a Utilitarian *means* to value positive experience even in the presence of extreme suffering insofar as that positive experience is \"good enough\". The more one doubles down on this value in the form of various suffering\/wellbeing arithmetic, the further we are from ethical insight, but the closer we are to insight into this person. I would be willing to bet that if you simply take this Utilitarian, and place them into the torture chamber for an undisclosed time, their intuitions about what matters will undoubtedly change because the torture **will** change them(It's both a good and bad thing that we can't do the science here to test this hypothesis). I admit my own bias here in *being* a Negative Utilitarian myself and failing to imagine the opposite being true quite as easily, but it's still absolutely conceivable. What about rule-based ethics? This too says little about the world other than that the person is deeply rule-oriented. People who are perhaps higher on the autism spectrum(predisposed to routine, order, etc) or on some kind of compulsive-behavior spectrum would likely subscribe to these ethics. Likewise, domineering people would mesh very well with absolute rules, because then their own representations of absolute rules can't be questioned from their vantage point. I'm sure there are exceptions to this rule, where perhaps certain autistic traits(high sensitivity) and certain life experiences would instead steer them closer to something like NU.\n\nThe conclusion as I see it is to do less ethics, and to do more psychology and science. Questions like \"What *motivates* this person?\", \"What does this person **value**?\"(And what *don't* they?), \"Is this person more interested in pragmatism or idealism?\" \"Which behavior\/idea is more *adaptive* from an evolutionary perspective?\", etc etc etc. Questions like these will illuminate ethics and maybe bridge our ethical intuitions.","send_replies":true,"spoiler":false,"stickied":false,"subreddit":"negativeutilitarians","subreddit_id":"t5_j5x1o","subreddit_subscribers":2925,"subreddit_type":"public","suggested_sort":null,"thumbnail":"self","thumbnail_height":null,"thumbnail_width":null,"title":"Both formal and informal approaches to ethics as they appear today, will never get us closer to understanding ethics. Here's a possible alternative.","top_awarded_type":null,"total_awards_received":0,"treatment_tags":[],"upvote_ratio":0.78,"url":"https:\/\/www.reddit.com\/r\/negativeutilitarians\/comments\/m3gfcc\/both_formal_and_informal_approaches_to_ethics_as\/","whitelist_status":"no_ads","wls":0}
